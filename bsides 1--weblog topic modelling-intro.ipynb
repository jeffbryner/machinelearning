{
 "metadata": {
  "name": "",
  "signature": "sha256:b729175e525cf9e9942cf07afd2fcef130560cc0ef61024a3e36277764416c49"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "#kludge fix for macports issue: https://trac.macports.org/ticket/31891\n",
      "sys.path.reverse() \n",
      "from gensim import corpora, models, similarities"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#http://radimrehurek.com/gensim/tut1.html#from-strings-to-vectors\n",
      "#sample set of 'documents' to convert to bag of words\n",
      "documents = [\"Human machine interface for lab abc computer applications\",\n",
      "             \"Another Document on machine learning applications\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stoplist = set('for a of the and on to in'.split())\n",
      "tokens = [[word for word in document.lower().split() if word not in stoplist]\n",
      "          for document in documents]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tokens"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "[['human', 'machine', 'interface', 'lab', 'abc', 'computer', 'applications'],\n",
        " ['another', 'document', 'machine', 'learning', 'applications']]"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictionary = corpora.Dictionary(tokens)\n",
      "print dictionary.token2id"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'learning': 9, 'abc': 0, 'another': 7, 'lab': 5, 'machine': 6, 'applications': 1, 'computer': 2, 'human': 3, 'interface': 4, 'document': 8}\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictionary.token2id['another']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "7"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_doc = \"Human computer human unknown learning\"\n",
      "new_vec = dictionary.doc2bow(new_doc.lower().split())\n",
      "print(new_vec)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(2, 1), (3, 2), (9, 1)]\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}